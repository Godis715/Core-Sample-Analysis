{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import copy\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Folder</th>\n",
       "      <th>Id</th>\n",
       "      <th>Ruin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Unload1</td>\n",
       "      <td>1000000</td>\n",
       "      <td>не разрушен</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Unload1</td>\n",
       "      <td>1000002</td>\n",
       "      <td>не разрушен</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Unload1</td>\n",
       "      <td>1000004</td>\n",
       "      <td>не разрушен</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Unload1</td>\n",
       "      <td>1000006</td>\n",
       "      <td>не разрушен</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Unload1</td>\n",
       "      <td>1000008</td>\n",
       "      <td>не разрушен</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>Unload1</td>\n",
       "      <td>1000010</td>\n",
       "      <td>не разрушен</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>Unload1</td>\n",
       "      <td>1000012</td>\n",
       "      <td>не разрушен</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>Unload1</td>\n",
       "      <td>1000014</td>\n",
       "      <td>не разрушен</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>Unload1</td>\n",
       "      <td>1000016</td>\n",
       "      <td>не разрушен</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>Unload1</td>\n",
       "      <td>1000018</td>\n",
       "      <td>не разрушен</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Folder       Id         Ruin\n",
       "0   Unload1  1000000  не разрушен\n",
       "2   Unload1  1000002  не разрушен\n",
       "4   Unload1  1000004  не разрушен\n",
       "6   Unload1  1000006  не разрушен\n",
       "8   Unload1  1000008  не разрушен\n",
       "10  Unload1  1000010  не разрушен\n",
       "12  Unload1  1000012  не разрушен\n",
       "14  Unload1  1000014  не разрушен\n",
       "16  Unload1  1000016  не разрушен\n",
       "18  Unload1  1000018  не разрушен"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'data/'\n",
    "df = pd.DataFrame(pd.read_csv(path+'data.csv'))\n",
    "df = df[df['PhotoType']=='ДС']\n",
    "df = df.loc[:,['Folder','Id','Ruin']]\n",
    "df = df[df['Ruin']!='частично разрушен']\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder    169\n",
      "Id        169\n",
      "Ruin      169\n",
      "dtype: int64\n",
      "Folder    0\n",
      "Id        0\n",
      "Ruin      0\n",
      "dtype: int64\n",
      "Folder    1472\n",
      "Id        1472\n",
      "Ruin      1472\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[df['Ruin']=='разрушен'].count())\n",
    "print(df[df['Ruin']=='частично разрушен'].count())\n",
    "print(df[df['Ruin']=='не разрушен'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "nor_indices = []\n",
    "\n",
    "for row in df.itertuples():\n",
    "    if row[3] == 'не разрушен':\n",
    "        nor_indices.append(row[0])    \n",
    "drop_indices = np.random.choice(nor_indices, \n",
    "                                1303, \n",
    "                                replace=False)\n",
    "\n",
    "df  = df.drop(drop_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/338\n",
      "100/338\n",
      "150/338\n",
      "200/338\n",
      "250/338\n",
      "300/338\n",
      "338/338\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "i = 1\n",
    "for row in df.itertuples():\n",
    "    img = Image.open(path+row[1]+'/data/'+str(row[2])+'.jpeg')\n",
    "    w, h = img.size\n",
    "    area = [w / 2 - 112, 5, w / 2 + 112, 229]\n",
    "    while h >= area[3] + 5:\n",
    "        cropped_img = img.crop(area)\n",
    "        X.append(transform(cropped_img))\n",
    "        if row[3] == 'не разрушен':\n",
    "            l = 0\n",
    "        else:\n",
    "            l = 1\n",
    "        y.append(l)\n",
    "        area[1] += 224\n",
    "        area[3] += 224\n",
    "        \n",
    "    if i % 50 == 0 or i == df.shape[0]:\n",
    "        print(str(i)+'/'+str(df.shape[0]))\n",
    "    i += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6712\n"
     ]
    }
   ],
   "source": [
    "print(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extract = True\n",
    "use_pretrained = True\n",
    "num_classes = 2\n",
    "\n",
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
    "set_parameter_requires_grad(model_ft, feature_extract)\n",
    "model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
    "model_ft.num_classes = num_classes\n",
    "input_size = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else \"cpu\"\n",
    "model_ft = model_ft.to(device)\n",
    "params_to_update = model_ft.parameters()\n",
    "optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[X[i], y[i]] for i in range(len(X))]\n",
    "test_indices = np.random.choice(np.arange(len(data)), 400, replace=False)\n",
    "data_test = [data[i] for i in test_indices]\n",
    "data = [data[i] for i in range(len(data)) if i not in test_indices]\n",
    "val_indices = np.random.choice(np.arange(len(data)), 400, replace=False)\n",
    "data_val = [data[i] for i in val_indices]\n",
    "data_train = [data[i] for i in range(len(data)) if i not in val_indices]\n",
    "data = {'train': data_train, 'val': data_val, 'test': data_test}\n",
    "batch_size = 8\n",
    "dataloaders_dict = {x: torch.utils.data.DataLoader(data[x], batch_size=batch_size, shuffle=True, num_workers=4) \n",
    "                    for x in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train() \n",
    "            else:\n",
    "                model.eval() \n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/14\n",
      "----------\n",
      "train Loss: 0.1623 Acc: 0.9411\n",
      "val Loss: 0.1130 Acc: 0.9550\n",
      "\n",
      "Epoch 1/14\n",
      "----------\n",
      "train Loss: 0.1238 Acc: 0.9579\n",
      "val Loss: 0.1417 Acc: 0.9550\n",
      "\n",
      "Epoch 2/14\n",
      "----------\n",
      "train Loss: 0.1146 Acc: 0.9601\n",
      "val Loss: 0.0990 Acc: 0.9550\n",
      "\n",
      "Epoch 3/14\n",
      "----------\n",
      "train Loss: 0.1044 Acc: 0.9645\n",
      "val Loss: 0.1043 Acc: 0.9625\n",
      "\n",
      "Epoch 4/14\n",
      "----------\n",
      "train Loss: 0.1051 Acc: 0.9631\n",
      "val Loss: 0.0907 Acc: 0.9625\n",
      "\n",
      "Epoch 5/14\n",
      "----------\n",
      "train Loss: 0.1027 Acc: 0.9685\n",
      "val Loss: 0.0977 Acc: 0.9500\n",
      "\n",
      "Epoch 6/14\n",
      "----------\n",
      "train Loss: 0.1000 Acc: 0.9655\n",
      "val Loss: 0.1278 Acc: 0.9625\n",
      "\n",
      "Epoch 7/14\n",
      "----------\n",
      "train Loss: 0.0995 Acc: 0.9657\n",
      "val Loss: 0.0914 Acc: 0.9600\n",
      "\n",
      "Epoch 8/14\n",
      "----------\n",
      "train Loss: 0.0971 Acc: 0.9672\n",
      "val Loss: 0.0996 Acc: 0.9600\n",
      "\n",
      "Epoch 9/14\n",
      "----------\n",
      "train Loss: 0.0951 Acc: 0.9660\n",
      "val Loss: 0.0959 Acc: 0.9600\n",
      "\n",
      "Epoch 10/14\n",
      "----------\n",
      "train Loss: 0.0960 Acc: 0.9685\n",
      "val Loss: 0.0843 Acc: 0.9675\n",
      "\n",
      "Epoch 11/14\n",
      "----------\n",
      "train Loss: 0.0919 Acc: 0.9696\n",
      "val Loss: 0.0857 Acc: 0.9575\n",
      "\n",
      "Epoch 12/14\n",
      "----------\n",
      "train Loss: 0.0920 Acc: 0.9701\n",
      "val Loss: 0.0878 Acc: 0.9600\n",
      "\n",
      "Epoch 13/14\n",
      "----------\n",
      "train Loss: 0.0933 Acc: 0.9689\n",
      "val Loss: 0.0915 Acc: 0.9575\n",
      "\n",
      "Epoch 14/14\n",
      "----------\n",
      "train Loss: 0.0914 Acc: 0.9680\n",
      "val Loss: 0.0904 Acc: 0.9550\n",
      "\n",
      "Training complete in 2m 46s\n",
      "Best val Acc: 0.967500\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 15\n",
    "model_ft, hist = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network: 97 %\n"
     ]
    }
   ],
   "source": [
    "testloader = torch.utils.data.DataLoader(data['test'], batch_size=batch_size, shuffle=False, num_workers=4) \n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model_ft(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
